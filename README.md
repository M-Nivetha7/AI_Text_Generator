# ğŸ§  AI Text Generator

![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-App-red.svg)
![AI](https://img.shields.io/badge/Generative-AI-green.svg)

A powerful AI Text Generator that blends Bigram based NLP with a GPT style neural generator, wrapped inside an interactive Streamlit Web App.  
This project helps explore how classical language models compare with modern deep learning approaches.

---

## ğŸš€ Features
- Bigram Text Generator: statistical and lightweight model
- GPT inspired Text Generator: neural based and more fluent output
- Streamlit Interface for quick text generation
- Automated logging of generated text
- Beginner friendly modular codebase

---

## ğŸ“‚ Project Structure

AI_Text_Generator/ # Main project directory
â”œâ”€â”€ data/ # Input and output storage
â”‚ â”œâ”€â”€ input.txt # Training input text
â”‚ â””â”€â”€ output.log # Generated text logs
â”œâ”€â”€ models/ # ML models
â”‚ â”œâ”€â”€ bigram.py # Bigram text generator
â”‚ â””â”€â”€ gpt.py # GPT based generator
â”œâ”€â”€ app/ # Streamlit application
â”‚ â”œâ”€â”€ streamlit_app.py # Main UI
â”‚ â””â”€â”€ testing_ui.py # Interface testing module
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Documentation

---

## ğŸ›  Installation

### Step 1: Clone the repository
git clone https://github.com/M-Nivetha7/AI_Text_Generator.git
cd AI_Text_Generator

shell
Copy code

### Step 2: Install required packages
pip install -r requirements.txt

shell
Copy code

### Step 3: Run the Streamlit Application
streamlit run app/streamlit_app.py

yaml
Copy code

---

## ğŸ§ª How to Use
Enter your prompt in the text input box  
Select either Bigram or GPT model  
Click Generate Text  
View your result instantly on the interface  
Check output.log for saved generations  

---

## ğŸ§  Behind the Scenes

### Bigram Model
A simple probability based approach  
Predicts each next word using word pairs observed in data

### GPT Inspired Generator
Learns contextual patterns using neural computation  
Produces more coherent and natural responses

---

## âœ¨ Learning Outcomes
Comparison of classical NLP and neural text generation models  
Tokenization and probability based language modeling  
Model development to app deployment using Streamlit  
Logging and debugging of text generation behavior  

---

## ğŸ¤ Contributions
Contributions are invited  
Share enhancements to the model, UI, documentation or data handling  

---

## ğŸ“¬ Contact
Author: **M. Nivetha**
